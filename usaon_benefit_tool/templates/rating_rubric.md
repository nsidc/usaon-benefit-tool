# Rating Rubrics

## Rating Rubrics for Societal Benefits - Performance


| Performance Rating | Interpretation | Example SBA/Key Objectives | Examples of Supporting Evidence for Performance of Applications |
|-------------------|----------------|---------------------------|---------------------------------------------------------------|
| **91-100** | **Ideal:** Application exceeds the requirements of this Key Objective | SBA Disaster Preparedness/Improve understanding of Earth systems to inform hazard identification and disaster prediction | The Arctic Report Vital Sign of the state of the Greenland Ice Sheet uses the Climate Data Record from the GRACE satellite to fully and accurately depicts mass loss from Greenland at a greater temporal resolution than needed to inform disaster prediction related to Greenland melt (Performance Context). It is widely (Impact Metric) used by planners (Instrumental Impact Action) and cited in their literature (Impact Metric). |
| **76-90** | **Fully Satisfied:** Application meets the requirements of this Key Objective | SBA Climate & Weather/Provide sector-specific weather predictions for economic productivity | AK Sea Ice Program's daily gridded sea ice concentration forecast (Performance Context) is used widely (Impact Metric) to inform mariners (Instrumental Impact Action), supporting economic activity in the Bering and Chukchi seas; NWS evaluations show high satisfaction from stakeholders (Impact Metric). |
| **60-75** | **Satisfied:** Application meets most of the requirements of this Key Objective | SBA Community Resilience/Mitigate the impacts of Arctic system changes on communities | The River Watch Community Decision Support Capacity creates a value-added information exchange between the NWS and communities collecting observations of springtime ice conditions along the Y-K river (Performance Context) so that communities can anticipate and mitigate the impacts (Instrumental Action Impact) of dangerous ice jams on critical infrastructure. Because of direct community involvement (Connectivity Action Impact), communities are able add considerable value to NWS watch and warning standard products. There are some spatial gaps around some communities (Gap). |
| **46-60** | **Partially Satisfied:** Application meets at least one requirement of this Key Objective | SBA Fundamental Understanding/Improve understanding of Arctic amplification of global warming | Surface Air Temperature Indicator of the Arctic Report Card has provided an annual assessment over a 15-year period of Arctic air temperatures (Performance Context) to support public understanding of Arctic change (Conceptual Understanding Impact Action). It has been cited in academic literature more than XX times and in news coverage more than YY times (Impact Metric), but the length of the record and its high uncertainty during wintertime (Gap) limit its utility for studying Arctic Amplification. |
| **30-45** | **Fair to Poor:** Application is periodically consulted to provide insights; under certain circumstances, it provides value to this Key Objective. | SBA Infrastructure & Operations/Ensure safe and secure infrastructure operations | The monthly summertime Sea Ice Outlook of the Sea Ice Prediction Network provides the most accurate multi-model seasonal outlook available for understanding expected ice concentrations in the Arctic (Performance Context); this information is relevant for planning safe operations and is referenced by mariners across sectors (Instrumental Impact Action). While concentrations are somewhat informative the user base is most interested in sea ice thickness which is not sufficiently accurate to be of use (Impact Metric). |
| **16-30** | **Poor:** Application is occasionally consulted to provide insights. It provides no stand-alone value in this context. | SBA Marine & Coastal Process/Improve understanding of the impacts of environmental change on Arctic marine and coastal ecosystems | Greenland Ice Sheet Indicator of the Arctic Report Card provides insights about freshwater discharge to adjacent seas (Performance Context) and can inform research on ecosystem impacts (Conceptual Understanding Impact); it is not presented at the temporal or spatial scales needed for process understanding (Gap). Preliminary information was presented at a science meeting and used to propose new work (Performance Metric). |
| **1-15** | **Very Poor:** Application is rarely if ever, consulted to provide insights into this key objective. | | |



## Rating Rubric for Societal Benefits - Criticality


| Criticality Level | Description | Example | Line Thickness |
|------------------|-------------|---------|----------------|
| **High (Essential)** | It would not be possible to meet this Key Objective within this Performance Context without this Application. | This application currently informs disaster prediction and response. It is widely used by planners and cited in their literature. | Thick |
| **Medium-high (Very Important)** | It would be difficult to meet this Key Objective within this Performance Context without this Application. | | Medium-thick |
| **Medium (Useful)** | The ability to meet this Key Objective within this Performance Context would be compromised without this Application. | Insights from retrospective analyses from the Sea Ice Prediction Network are used to improve routine seasonal forecasts of sea ice. They were shared in publications and at a workshop that involved model developers. | Medium |
| **Medium-Low (Somewhat Useful)** | The ability to meet this Key Objective within this Performance Context would be a bit reduced without this Application. | | Medium-thin |
| **Low (Nice to Have)** | Has some link to this societal benefit area, but is not widely used or consulted | The Arctic Report Card indicators link to food security but do not actively inform decisions related to food security. | Thin |

---


## Rating Rubrics for Inputs (Observing Systems and Intermediate Products) - Performance


| Performance Rating | Interpretation |
|-------------------|----------------|
| **91-100** | **Ideal:** Intermediate Product or Observing System input exceeds the requirements |
| **76-90** | **Fully Satisfied:** Intermediate Product or Observing System input meets the requirements |
| **60-75** | **Satisfied:** Intermediate Product or Observing System input meets most of the requirements |
| **46-60** | **Partially Satisfied:** Intermediate Product or Observing System input meets at least one requirement |
| **30-45** | **Fair to Poor:** Intermediate Product or Observing System is periodically consulted to provide insights; under certain circumstances, it provides value. |
| **16-30** | **Poor:** Intermediate Product or Observing System is occasionally consulted to provide insights. It provides no stand-alone value in this context. |
| **1-15** | **Very Poor:** Intermediate Product or Observing System is rarely if ever, consulted to provide insights into this key objective. |
| | **Prefer not to rate** |



## Rating Rubrics for Inputs (Observing Systems and Intermediate Products) - Criticality


| Criticality Level | Description | Line Thickness |
|------------------|-------------|----------------|
| **High (Essential)** | It would not be possible to produce this Application or Intermediate Product within this Performance Context without this Input. | Thick |
| **Medium-high (Very Important)** | Loss of this Input would significantly reduce the performance of this Application or Intermediate product. | Medium-thick |
| **Medium (Useful)** | Loss of this Input would reduce the performance of this Application or Intermediate product, but it would still have some value. | Medium |
| **Medium-Low (Somewhat Useful)** | Loss of this Input would reduce the performance of this Application or Intermediate product, but it would still have considerable value. | Medium-thin |
| **Low (Nice to Have)** | This Input is nice to have, but is not widely used or consulted for this Application or Intermediate product. | Thin |
